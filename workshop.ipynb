{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "You are banned from using loops (`for` or `while` or any other) for this entire workshop!\n",
    "\n",
    "You shouldn't be using loops almost ever with pandas in any case, so break out of the habit now.\n",
    "\n",
    "## 1. DataFrame basics\n",
    "\n",
    "\n",
    "Consider the following Python dictionary `data` and Python list `labels`:\n",
    "\n",
    "``` python\n",
    "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
    "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "```\n",
    "(This is just some meaningless data I made up with the theme of animals and trips to a vet.)\n",
    "\n",
    "**1.** Create a DataFrame `df` from this dictionary `data` which has the index `labels`.\n",
    "\n",
    "**2.** Select only the rows where visits are 3 or more. Which types of animals are these?\n",
    "\n",
    "**3.** Select the rows where visists are 3 and the animal is a cat\n",
    "\n",
    "**4.** Calculate the sum of all visits in `df` (i.e. the total number of visits).\n",
    "\n",
    "**5.** Calculate the mean age for each different animal in `df`.\n",
    "\n",
    "**6.** Append a new row 'k' to `df` with your choice of values for each column. Then delete that row to return the original DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rows with three visits are:\n",
      "  animal  age  visits priority labels\n",
      "1    cat  3.0       3      yes      b\n",
      "3    dog  NaN       3      yes      d\n",
      "5    cat  2.0       3       no      f\n",
      "The rows with three visits and a cat are:\n",
      "  animal  age  visits priority labels\n",
      "1    cat  3.0       3      yes      b\n",
      "5    cat  2.0       3       no      f\n",
      "There were a total of: 19 visits\n",
      "The average age is 3.4375\n",
      "   animal     age  visits priority labels\n",
      "0     cat     2.5       1      yes      a\n",
      "1     cat       3       3      yes      b\n",
      "2   snake     0.5       2       no      c\n",
      "3     dog     NaN       3      yes      d\n",
      "4     dog       5       2       no      e\n",
      "5     cat       2       3       no      f\n",
      "6   snake     4.5       1       no      g\n",
      "7     cat     NaN       1      yes      h\n",
      "8     dog       7       2       no      i\n",
      "9     dog       3       1       no      j\n",
      "10      4  parrot       2       no      k\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\n",
    "        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],\n",
    "        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "data['labels'] = labels\n",
    "\n",
    "\"\"\"\n",
    "1:\n",
    "\"\"\"\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('labels')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "2:\n",
    "\"\"\"\n",
    "three_visits = df.loc[df.visits >= 3]\n",
    "print(\"The rows with three visits are:\")\n",
    "print(three_visits)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "3:\n",
    "\"\"\"\n",
    "three_vists_and_a_cat = df.query('visits == 3 & animal == \"cat\"')\n",
    "print(\"The rows with three visits and a cat are:\")\n",
    "print(three_vists_and_a_cat)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "4:\n",
    "\"\"\"\n",
    "sum_of_all_visits = df.visits.sum()\n",
    "print(\"There were a total of: {s_v} visits\".format(s_v=sum_of_all_visits))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "5:\n",
    "\"\"\"\n",
    "mean_of_ages = df.age.mean()\n",
    "print(\"The average age is {s_v}\".format(s_v=mean_of_ages))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "6:\n",
    "\"\"\"\n",
    "df.loc[len(df.index)] = [4,'parrot',2, 'no', 'k']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Shifty problem\n",
    "\n",
    "You have a DataFrame `df` with a column 'A' of integers. For example:\n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})\n",
    "```\n",
    "\n",
    "How do you filter out rows which contain the same integer as the row immediately above?\n",
    "\n",
    "You should be left with a column containing the following values:\n",
    "\n",
    "```python\n",
    "1, 2, 3, 4, 5, 6, 7\n",
    "```\n",
    "\n",
    "### Hint: use the `shift()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]})\n",
    "df.shift()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 columns sum min\n",
    "\n",
    "Suppose you have DataFrame with 10 columns of real numbers, for example:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))\n",
    "```\n",
    "Which column of numbers has the smallest sum? Return that column's label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    2.038144\n",
      "b    2.972550\n",
      "c    2.182087\n",
      "d    1.412166\n",
      "e    2.578099\n",
      "f    1.593930\n",
      "g    2.613984\n",
      "h    3.224152\n",
      "i    1.674383\n",
      "j    2.007061\n",
      "dtype: float64\n",
      "The colum with the smallest sum is d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(np.random.random(size=(5, 10)), columns=list('abcdefghij'))\n",
    "summed = df.sum(axis=0)\n",
    "min_index = summed.idxmin()\n",
    "\n",
    "print(summed)\n",
    "print(\"The colum with the smallest sum is {label}\".format(label=min_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Duplicates\n",
    "\n",
    "How do you count how many unique rows a DataFrame has (i.e. ignore all rows that are duplicates)?\n",
    "\n",
    "**hint:** There's a method for to find duplicate rows for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first  second  third\n",
      "0      0       0      0\n",
      "1      0       1      3\n",
      "3      0       2      6\n",
      "4      4       4      4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'first': [0,0,0,0,4],\n",
    "    'second': [0,1, 0, 2, 4],\n",
    "    'third': [0,3, 0, 6, 4]\n",
    "})\n",
    "uniques = df.drop_duplicates()\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Group Values\n",
    "\n",
    "A DataFrame has a column of groups 'grps' and and column of integer values 'vals': \n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'grps': list('aaabbcaabcccbbc'), \n",
    "                   'vals': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n",
    "```\n",
    "For each *group*, find the sum of the three greatest values.  You should end up with the answer as follows:\n",
    "```\n",
    "grps\n",
    "a    409\n",
    "b    156\n",
    "c    345\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grps\n",
      "a    409\n",
      "b    156\n",
      "c    345\n",
      "Name: vals, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'grps': list('aaabbcaabcccbbc'), \n",
    "                   'vals': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n",
    "\n",
    "result = df.groupby('grps')['vals'].apply(lambda group: group.nlargest(3).sum())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleaning Data\n",
    "\n",
    "### Making a DataFrame easier to work with\n",
    "\n",
    "It happens all the time: someone gives you data containing malformed strings, Python, lists and missing data. How do you tidy it up so you can get on with the analysis?\n",
    "\n",
    "Take this monstrosity as the DataFrame to use in the following puzzles:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', \n",
    "                               'Budapest_PaRis', 'Brussels_londOn'],\n",
    "              'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
    "              'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
    "                   'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', \n",
    "                               '12. Air France', '\"Swiss Air\"']})\n",
    "```\n",
    "\n",
    "Formatted, it looks like this:\n",
    "\n",
    "```\n",
    "            From_To  FlightNumber  RecentDelays              Airline\n",
    "0      LoNDon_paris       10045.0      [23, 47]               KLM(!)\n",
    "1      MAdrid_miLAN           NaN            []    <Air France> (12)\n",
    "2  londON_StockhOlm       10065.0  [24, 43, 87]  (British Airways. )\n",
    "3    Budapest_PaRis           NaN          [13]       12. Air France\n",
    "4   Brussels_londOn       10085.0      [67, 32]          \"Swiss Air\"\n",
    "```\n",
    "\n",
    "**1.** Some values in the the **FlightNumber** column are missing (they are `NaN`). These numbers are meant to increase by 10 with each row so 10055 and 10075 need to be put in place. Modify `df` to fill in these missing numbers and make the column an integer column (instead of a float column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            From_To  FlightNumber  RecentDelays              Airline\n",
      "0      LoNDon_paris       10045.0      [23, 47]               KLM(!)\n",
      "1      MAdrid_miLAN       10055.0            []    <Air France> (12)\n",
      "2  londON_StockhOlm       10065.0  [24, 43, 87]  (British Airways. )\n",
      "3    Budapest_PaRis       10075.0          [13]       12. Air France\n",
      "4   Brussels_londOn       10085.0      [67, 32]          \"Swiss Air\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', 'Budapest_PaRis', 'Brussels_londOn'],\n",
    "    'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
    "    'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
    "    'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', '12. Air France', '\"Swiss Air\"']\n",
    "})\n",
    "# print(df)\n",
    "\"\"\"\n",
    "Get all Flight Routes\n",
    "\"\"\"\n",
    "unique_indexes = pd.Index(df.From_To)\n",
    "\"\"\"\n",
    "Get the id of the first route\n",
    "\"\"\"\n",
    "starting_fn = df.iloc[0].FlightNumber\n",
    "\n",
    "def apply_to_cell(x):\n",
    "    return (unique_indexes.get_loc(x) * 10) + starting_fn\n",
    "\n",
    "\"\"\"\n",
    "Apply our lambda to each FlightNumber cell\n",
    "\"\"\"\n",
    "df.FlightNumber = df.From_To.apply(apply_to_cell)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 column splitting\n",
    "\n",
    "The **From\\_To** column would be better as two separate columns! Split each string on the underscore delimiter `_` to make two new columns `From` and `To` to your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            From_To  FlightNumber  RecentDelays              Airline  \\\n",
      "0      LoNDon_paris       10045.0      [23, 47]               KLM(!)   \n",
      "1      MAdrid_miLAN           NaN            []    <Air France> (12)   \n",
      "2  londON_StockhOlm       10065.0  [24, 43, 87]  (British Airways. )   \n",
      "3    Budapest_PaRis           NaN          [13]       12. Air France   \n",
      "4   Brussels_londOn       10085.0      [67, 32]          \"Swiss Air\"   \n",
      "\n",
      "       From         To  \n",
      "0    LoNDon      paris  \n",
      "1    MAdrid      miLAN  \n",
      "2    londON  StockhOlm  \n",
      "3  Budapest      PaRis  \n",
      "4  Brussels     londOn  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', 'Budapest_PaRis', 'Brussels_londOn'],\n",
    "    'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
    "    'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
    "    'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )', '12. Air France', '\"Swiss Air\"']\n",
    "})\n",
    "\n",
    "def create_from_to(df):\n",
    "    \n",
    "    def add_from_to(row): \n",
    "        elems = row.split('_')\n",
    "        return pd.Series({'From': elems[0], 'To': elems[1]})\n",
    "    \n",
    "    # We add From and To onto the original dataframe\n",
    "    return df.merge(df.From_To.apply(add_from_to), left_index=True, right_index=True)\n",
    "\n",
    "with_from_to = create_from_to(df)\n",
    "\n",
    "print(with_from_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Clean Text\n",
    "\n",
    "Make the text in your dataframe:\n",
    "\n",
    "- From and To columns should be lowercase with only first letter capitalized\n",
    "\n",
    "- In the **Airline** column, you can see some extra puctuation and symbols have appeared around the airline names. Pull out just the airline name. E.g. `'(British Airways. )'` should become `'British Airways'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            From_To  FlightNumber  RecentDelays          Airline      From  \\\n",
      "0      LoNDon_paris       10045.0      [23, 47]              KLM    London   \n",
      "1      MAdrid_miLAN           NaN            []       Air France    Madrid   \n",
      "2  londON_StockhOlm       10065.0  [24, 43, 87]  British Airways    London   \n",
      "3    Budapest_PaRis           NaN          [13]       Air France  Budapest   \n",
      "4   Brussels_londOn       10085.0      [67, 32]        Swiss Air  Brussels   \n",
      "\n",
      "          To  \n",
      "0      Paris  \n",
      "1      Milan  \n",
      "2  Stockholm  \n",
      "3      Paris  \n",
      "4     London  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def capitalize_from_to(df):\n",
    "    df['From'] = df['From'].str.title()\n",
    "    df['To'] = df['To'].str.title()\n",
    "    \n",
    "\n",
    "# We remove all special characters, and numbers, then make sure there is no trailing\n",
    "# and leading whitespace\n",
    "def cleanup_airport(df):\n",
    "    df['Airline'] = df['Airline'].apply(lambda row: re.sub(r\"[^a-zA-Z]+\", ' ', row).strip())\n",
    "\n",
    "capitalize_from_to(with_from_to)\n",
    "cleanup_airport(with_from_to)\n",
    "\n",
    "\n",
    "print(with_from_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.1: Column Splitting\n",
    "\n",
    "Given the unemployment data in `data/country_total.csv`, split the `month` column into two new columns: a `year` column and a `month` column, both integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      country seasonality    month  unemployment  unemployment_rate\n",
      "0          at         nsa  1993.01        171000                4.5\n",
      "1          at         nsa  1993.02        175000                4.6\n",
      "2          at         nsa  1993.03        166000                4.4\n",
      "3          at         nsa  1993.04        157000                4.1\n",
      "4          at         nsa  1993.05        147000                3.9\n",
      "...       ...         ...      ...           ...                ...\n",
      "20791      uk       trend  2010.06       2429000                7.7\n",
      "20792      uk       trend  2010.07       2422000                7.7\n",
      "20793      uk       trend  2010.08       2429000                7.7\n",
      "20794      uk       trend  2010.09       2447000                7.8\n",
      "20795      uk       trend  2010.10       2455000                7.8\n",
      "\n",
      "[20796 rows x 5 columns]\n",
      "      country seasonality  unemployment  unemployment_rate month  year\n",
      "0          at         nsa        171000                4.5    01  1993\n",
      "1          at         nsa        175000                4.6    02  1993\n",
      "2          at         nsa        166000                4.4    03  1993\n",
      "3          at         nsa        157000                4.1    04  1993\n",
      "4          at         nsa        147000                3.9    05  1993\n",
      "...       ...         ...           ...                ...   ...   ...\n",
      "20791      uk       trend       2429000                7.7    06  2010\n",
      "20792      uk       trend       2422000                7.7    07  2010\n",
      "20793      uk       trend       2429000                7.7    08  2010\n",
      "20794      uk       trend       2447000                7.8    09  2010\n",
      "20795      uk       trend       2455000                7.8     1  2010\n",
      "\n",
      "[20796 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/country_total.csv')\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "def create_year_month(df):\n",
    "    \n",
    "    def add_month_year(row): \n",
    "        elems = str(row).split('.')\n",
    "        return pd.Series({'month_t': elems[1], 'year': elems[0]})\n",
    "    \n",
    "    # We add From and To onto the original dataframe\n",
    "    new_df = df.merge(df.month.apply(add_month_year), left_index=True, right_index=True)\n",
    "    new_df = new_df.drop(['month'], axis=1)\n",
    "    return new_df.rename(columns={'month_t': 'month'})\n",
    "    \n",
    "df = create_year_month(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Group Statistics\n",
    "\n",
    "Given the unemployment data in `data/country_sex_age.csv`, give the average unemployment rate for:\n",
    "\n",
    "- Each gender\n",
    "- Each Age Group\n",
    "- Both Together\n",
    "\n",
    "**HINT:** The `seasonality` column makes it such that the data is repeated for each method of calculating unemployment (`nsa`, `trend`, etc.). Can you ignore this and group over it? Or should you take the average for each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gender       mean\n",
      "0      f  12.982629\n",
      "1      m  11.671026\n",
      "  age_group       mean\n",
      "0    y25-74   6.905394\n",
      "1    y_lt25  17.774057\n",
      "  gender age_group       mean\n",
      "0      f    y25-74   7.566771\n",
      "1      f    y_lt25  18.457435\n",
      "2      m    y25-74   6.244016\n",
      "3      m    y_lt25  17.098036\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "df = pd.read_csv('data/country_sex_age.csv')\n",
    "# print(df)\n",
    "unique_genders = df['sex'].unique()\n",
    "unique_age_group = df['age_group'].unique()\n",
    "unique_gender_age_groups = list(product(unique_genders, unique_age_group))\n",
    "\n",
    "genders = pd.DataFrame({'gender': unique_genders})\n",
    "age_groups = pd.DataFrame({'age_group': unique_age_group})\n",
    "# We create a third dataframe with the combinations of each unique gender and age group\n",
    "gender_age_groups = pd.DataFrame(data=unique_gender_age_groups, columns=['gender','age_group'])\n",
    "\n",
    "\n",
    "# We apply a merge and apply to each dataframe to create the means columns from data in the csv file\n",
    "\n",
    "genders = genders.merge(\n",
    "    genders.gender.apply(\n",
    "        lambda row: pd.Series(\n",
    "            {\n",
    "                'mean': df.loc[df['sex'] == row, 'unemployment_rate'].mean()\n",
    "            }\n",
    "        )\n",
    "    ),\n",
    "    left_index=True, right_index=True\n",
    ")\n",
    "age_groups = age_groups.merge(\n",
    "    age_groups.age_group.apply(\n",
    "        lambda row: pd.Series(\n",
    "            {\n",
    "                'mean': df.loc[df['age_group'] == row, 'unemployment_rate'].mean()\n",
    "            }\n",
    "        )\n",
    "    ),\n",
    "    left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "gender_age_groups = gender_age_groups.merge(\n",
    "    gender_age_groups.apply(\n",
    "        lambda row: pd.Series(\n",
    "            {\n",
    "                'mean': df.loc[(df['sex'] == row.gender) & (df['age_group'] == row.age_group), 'unemployment_rate'].mean()\n",
    "            }\n",
    "        ),\n",
    "        axis=1\n",
    "    ),\n",
    "    left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "print(genders)\n",
    "print(age_groups)\n",
    "print(gender_age_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Estimating group size\n",
    "\n",
    "Given that we have the unemployment **rate** as a % of total population, and the number of total unemployed, we can estimate the total population.\n",
    "\n",
    "Give an estimate of the total population for men and women in each age group.\n",
    "\n",
    "Does this change depending on the unemployment seasonality calculation method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BY GENDER GROUPS ONLY:\n",
      "sex  age_group\n",
      "f    y25-74       3.220602e+06\n",
      "     y_lt25       5.665826e+05\n",
      "m    y25-74       4.357668e+06\n",
      "     y_lt25       6.679826e+05\n",
      "Name: pop_est, dtype: float64\n",
      " \n",
      "BY TIME PERIOD:\n",
      "sex  age_group  month  \n",
      "f    y25-74     1983.01    2.833058e+06\n",
      "                1983.02    2.841320e+06\n",
      "                1983.03    2.841420e+06\n",
      "                1983.04    2.855877e+06\n",
      "                1983.05    2.853827e+06\n",
      "                               ...     \n",
      "m    y_lt25     2010.08    5.692591e+05\n",
      "                2010.09    5.687628e+05\n",
      "                2010.10    6.319955e+05\n",
      "                2010.11    4.636428e+05\n",
      "                2010.12    4.612474e+05\n",
      "Name: pop_est, Length: 1344, dtype: float64\n",
      " \n",
      "The variance of seasonal unemployed males over time is 206702.405002405 +/- 315546.4107734553\n",
      "The variance of NON-seasonal unemployed males over time is 289391.5824915825 +/- 396777.87992010266\n",
      "The variance of seasonal unemployed females over time is 188137.56613756614 +/- 284589.84048763727\n",
      "The variance of NON seasonal unemployed females over time is 263423.4728234728 +/- 355420.8497797823\n",
      "The seasonality is not significantly impactfull for males\n",
      "The seasonality is not significantly impactfull for females\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "total population for men and women in each age group\n",
    "\"\"\"\n",
    "# Let's add a column of estimated total populations\n",
    "df['pop_est'] = (100 / df['unemployment_rate']) * df['unemployment']\n",
    "unemployed_by_genders_time_cumulative = df.groupby(['sex', 'age_group'])['pop_est'].mean()\n",
    "\n",
    "\"\"\"\n",
    "total population for men and women in each age group over each time period\n",
    "\"\"\"\n",
    "df['pop_est'] = (100 / df['unemployment_rate']) * df['unemployment']\n",
    "unemployed_by_genders_over_time = df.groupby(['sex', 'age_group', 'month'])['pop_est'].mean()\n",
    "\n",
    "\n",
    "print(\"BY GENDER GROUPS ONLY:\")\n",
    "print(unemployed_by_genders_time_cumulative)\n",
    "print(\" \")\n",
    "print(\"BY TIME PERIOD:\")\n",
    "print(unemployed_by_genders_over_time)\n",
    "print(\" \")\n",
    "\n",
    "\"\"\"\n",
    "unemployment seasonality calculation method\n",
    "\"\"\"\n",
    "# We check our dataframe of unemployed_by_gender_age_groups_over_time, since this df\n",
    "# Is already filtered\n",
    "# To remove seasonal variation, we will exclude data for sample populations under the age\n",
    "# of 25, meaning, we will only consider adults in the workforce, who we\n",
    "# assume to no longer be in school.\n",
    "# First we calculate our seasonal baselines\n",
    "\n",
    "seasonal_unemployed_males = df.loc[df['sex'] == 'm']\n",
    "seasonal_unemployed_females = df.loc[df['sex'] == 'f']\n",
    "\n",
    "seasonal_std_males_ot = seasonal_unemployed_males['unemployment'].std()\n",
    "seasonal_average_males_ot = seasonal_unemployed_males['unemployment'].mean()\n",
    "seasonal_std_females_ot = seasonal_unemployed_females['unemployment'].std()\n",
    "seasonal_average_females_ot = seasonal_unemployed_females['unemployment'].mean()\n",
    "\n",
    "\n",
    "# un-seasonal dataframes\n",
    "unemployed_males = seasonal_unemployed_males.loc[seasonal_unemployed_males['age_group'] == 'y25-74']\n",
    "unemployed_females = seasonal_unemployed_females.loc[seasonal_unemployed_females['age_group'] == 'y25-74']\n",
    "\n",
    "\n",
    "std_males_ot = unemployed_males['unemployment'].std()\n",
    "average_males_ot = unemployed_males['unemployment'].mean()\n",
    "std_females_ot = unemployed_females['unemployment'].std()\n",
    "average_females_ot = unemployed_females['unemployment'].mean()\n",
    "\n",
    "\n",
    "print(\"The variance of seasonal unemployed males over time is {v} +/- {std}\".format(\n",
    "    v=seasonal_average_males_ot,\n",
    "    std=seasonal_std_males_ot\n",
    "))\n",
    "print(\"The variance of NON-seasonal unemployed males over time is {v} +/- {std}\".format(\n",
    "    v=average_males_ot,\n",
    "    std=std_males_ot\n",
    "))\n",
    "print(\"The variance of seasonal unemployed females over time is {v} +/- {std}\".format(\n",
    "    v=seasonal_average_females_ot,\n",
    "    std=seasonal_std_females_ot\n",
    "))\n",
    "print(\"The variance of NON seasonal unemployed females over time is {v} +/- {std}\".format(\n",
    "    v=average_females_ot,\n",
    "    std=std_females_ot\n",
    "))\n",
    "\n",
    "\"\"\"\n",
    "We can determine that the seasonal calculation has no impact if the standard deviations\n",
    "of seasonal vs non-seasonal pools of the population have an overlap\n",
    "\"\"\"\n",
    "\n",
    "# Males\n",
    "seasonal_males_min_range = seasonal_average_males_ot - seasonal_std_males_ot\n",
    "males_range = average_males_ot + std_males_ot\n",
    "overlap = seasonal_males_min_range <= males_range\n",
    "print(\"The seasonality is not significantly impactfull for males\" if overlap else \"The seasonality is significantly impactfull for males\")\n",
    "\n",
    "\n",
    "# Males\n",
    "seasonal_females_min_range = seasonal_average_females_ot - seasonal_std_females_ot\n",
    "females_range = average_females_ot + std_females_ot\n",
    "fe_overlap = seasonal_females_min_range <= females_range\n",
    "print(\"The seasonality is not significantly impactfull for females\" if fe_overlap else \"The seasonality is significantly impactfull for females\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tennis\n",
    "\n",
    "In `data/tennis.csv` you have games that Roger Federer played against various opponents. Questions:\n",
    "\n",
    "1. How many games did Federer win?\n",
    "\n",
    "2. What is Federer's win/loss ratio?\n",
    "\n",
    "3. Who were Federer's top 5 opponents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federer has won 903 games\n",
      "Federer's win/loss ratio is 4.36231884057971\n",
      "Federer's top 5 oponents are\n",
      "Novak Djokovic (SRB)       29\n",
      "Rafael Nadal (ESP)         28\n",
      "Lleyton Hewitt (AUS)       26\n",
      "Andy Roddick (USA)         24\n",
      "Nikolay Davydenko (RUS)    19\n",
      "Name: opponent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('data/tennis.csv')\n",
    "df = df1.loc[df1['opponent'] != 'Bye']\n",
    "\n",
    "\n",
    "federer_wins = df.loc[df['winner'] == 'Roger Federer']['winner'].count()\n",
    "federer_losses = df['winner'].count() - federer_wins\n",
    "oponnents = df['opponent'].value_counts()\n",
    "top5 = oponnents.nlargest(5)\n",
    "print(\"Federer has won {co} games\".format(co=federer_wins))\n",
    "print(\"Federer's win/loss ratio is {r}\".format(r=federer_wins/federer_losses))\n",
    "print(\"Federer's top 5 oponents are\")\n",
    "print(top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Over time\n",
    "\n",
    "1. What was Federer's best year? In terms of money, and then in terms of number of wins\n",
    "\n",
    "2. Did Federer get better or worse over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year      earned  wins  earning_per_win\n",
      "0   1998     21600.0   2.0     10800.000000\n",
      "1   1999    365975.0  28.0     13070.535714\n",
      "2   2000   1023498.0  30.0     34116.600000\n",
      "3   2001   2444072.0  46.0     53132.000000\n",
      "4   2002   6696200.0  55.0    121749.090909\n",
      "5   2003  19881618.0  74.0    268670.513514\n",
      "6   2004  38593375.0  70.0    551333.928571\n",
      "7   2005  35922490.0  80.0    449031.125000\n",
      "8   2006  50157595.0  90.0    557306.611111\n",
      "9   2007  51186795.0  67.0    763982.014925\n",
      "10  2008  22140900.0  63.0    351442.857143\n",
      "11  2009  32362250.0  59.0    548512.711864\n",
      "12  2010  34625940.0  66.0    524635.454545\n",
      "13  2011  24006110.0  61.0    393542.786885\n",
      "14  2012  32048985.0  67.0    478343.059701\n",
      "Federer has gotten better over time\n",
      "But his best year in terms of earnings was 2007.0\n",
      "And his best year in terms of wins was 2006.0\n",
      "And his best year in terms of earning per win was 2007.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-louismurphy/opt/anaconda3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "df.dropna(subset=['tournament prize money'])\n",
    "df = df.loc[df['tournament prize money'] != '']\n",
    "\n",
    "df['tournament prize money'].replace(r'[\\$,a-zA-Z]', '', regex=True)\n",
    "df['tournament prize money'].apply(lambda row: 0.0 if row == '' else row)\n",
    "df['tournament prize money'] = df['tournament prize money'].astype(float)\n",
    "fed_wins = df.loc[df['winner'] == 'Roger Federer']\n",
    "\n",
    "def check_results():\n",
    "    sums = pd.DataFrame({\n",
    "        'year': fed_wins['year'].unique()\n",
    "    })\n",
    "\n",
    "    # We check how much money earned and how many wins\n",
    "    sums = sums.merge(\n",
    "        sums.year.apply(\n",
    "            lambda year: pd.Series({\n",
    "                'earned': fed_wins.loc[fed_wins['year'] == year]['tournament prize money'].sum(),\n",
    "                'wins': fed_wins.loc[fed_wins['year'] == year]['tournament prize money'].count()\n",
    "            })\n",
    "        ),\n",
    "        left_index=True, \n",
    "        right_index=True\n",
    "    )\n",
    "    sums['earning_per_win'] = sums['earned'] / sums['wins']\n",
    "    # fed_wins.groupby(['year','tournament prize money'])['tournament prize money'].sum()\n",
    "    top_year = sums.nlargest(1, 'earned').iloc[0]['year']\n",
    "    top_year_wins = sums.nlargest(1, 'wins').iloc[0]['year']\n",
    "    top_year_earning_per_wins = sums.nlargest(1, 'earning_per_win').iloc[0]['year']\n",
    "    lin_reg = stats.linregress(sums['year'], sums['wins'])\n",
    "    print(sums)\n",
    "    print(\"Federer has gotten better over time\" if lin_reg.slope > 0 else \"Federer has not gotten better over time\")\n",
    "    print(\"But his best year in terms of earnings was {year}\".format(year=top_year))\n",
    "    print(\"And his best year in terms of wins was {y}\".format(y=top_year_wins))\n",
    "    print(\"And his best year in terms of earning per win was {y}\".format(y=top_year_earning_per_wins))\n",
    "\n",
    "check_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Total money won\n",
    "\n",
    "In the data, you'll find the `tournament round`, one value of which, `F` indicates the final.\n",
    "\n",
    "Assuming Federer wins the money in the `tournament prize money` if he wins a final in a tournament, how much money has Federer made in tournaments in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year     earned  wins  earning_per_win\n",
      "0   1999    14400.0   1.0     14400.000000\n",
      "1   2001    54000.0   1.0     54000.000000\n",
      "2   2002   540600.0   3.0    180200.000000\n",
      "3   2003  3026502.0   7.0    432357.428571\n",
      "4   2004  6229377.0  11.0    566307.000000\n",
      "5   2005  4733250.0  11.0    430295.454545\n",
      "6   2006  7221635.0  12.0    601802.916667\n",
      "7   2007  7245735.0   8.0    905716.875000\n",
      "8   2008  1819800.0   4.0    454950.000000\n",
      "9   2009  2938500.0   4.0    734625.000000\n",
      "10  2010  4561045.0   5.0    912209.000000\n",
      "11  2011  2579000.0   4.0    644750.000000\n",
      "12  2012  3971120.0   6.0    661853.333333\n",
      "Federer has gotten better over time\n",
      "But his best year in terms of earnings was 2007.0\n",
      "And his best year in terms of wins was 2006.0\n",
      "And his best year in terms of earning per win was 2010.0\n"
     ]
    }
   ],
   "source": [
    "fed_wins = fed_wins.loc[fed_wins['tournament round'] == \"F\"]\n",
    "# print(fed_tourney_wins)\n",
    "check_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
